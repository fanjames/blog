{"meta":{"title":"传习录","subtitle":"用文字记录时间","description":null,"author":"fanhua","url":"https://fanjames.github.io/blog"},"pages":[{"title":"About me","date":"2018-05-05T10:13:45.000Z","updated":"2020-07-11T13:24:17.811Z","comments":true,"path":"about/index.html","permalink":"https://fanjames.github.io/blog/about/index.html","excerpt":"","text":"生于草莽，负笈十载，略晓"},{"title":"文章类别","date":"2018-05-05T10:02:52.000Z","updated":"2020-07-11T13:24:17.811Z","comments":true,"path":"categories/index.html","permalink":"https://fanjames.github.io/blog/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-05-05T10:02:14.000Z","updated":"2020-07-11T13:24:17.819Z","comments":true,"path":"tags/index.html","permalink":"https://fanjames.github.io/blog/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"知识图谱构建","slug":"知识图谱构建","date":"2020-07-05T12:38:20.000Z","updated":"2020-07-11T13:24:17.807Z","comments":true,"path":"2020/07/05/知识图谱构建/","link":"","permalink":"https://fanjames.github.io/blog/2020/07/05/知识图谱构建/","excerpt":"为了构建中文百科类知识图谱，我们参考漆桂林老师团队做的zhishi.me。目标是包含百度百科、互动百科、中文wiki百科的知识，千万级实体数量和亿级别的关系数目。目前已完成百度百科和互动百科部分，其中百度百科词条4,190,390个，存入 neo4j 后得到节点 10,416,647个，关系 37,317,167 条，属性 45,049,533个。互动百科词条3,677,150个, 存入 neo4j中得到节点 6,081,723个，关系19,054,289个，属性16,917,984个。总计节点 16,498,370个，关系 56,371,456个，属性 61,967,517个。","text":"为了构建中文百科类知识图谱，我们参考漆桂林老师团队做的zhishi.me。目标是包含百度百科、互动百科、中文wiki百科的知识，千万级实体数量和亿级别的关系数目。目前已完成百度百科和互动百科部分，其中百度百科词条4,190,390个，存入 neo4j 后得到节点 10,416,647个，关系 37,317,167 条，属性 45,049,533个。互动百科词条3,677,150个, 存入 neo4j中得到节点 6,081,723个，关系19,054,289个，属性16,917,984个。总计节点 16,498,370个，关系 56,371,456个，属性 61,967,517个。","categories":[{"name":"编程","slug":"编程","permalink":"https://fanjames.github.io/blog/categories/编程/"},{"name":"知识图谱","slug":"编程/知识图谱","permalink":"https://fanjames.github.io/blog/categories/编程/知识图谱/"}],"tags":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://fanjames.github.io/blog/tags/知识图谱/"},{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://fanjames.github.io/blog/tags/knowledge-graph/"}]},{"title":"在浏览器中显示视频流","slug":"在浏览器中显示视频流","date":"2018-07-15T10:07:09.000Z","updated":"2020-07-11T13:24:17.807Z","comments":true,"path":"2018/07/15/在浏览器中显示视频流/","link":"","permalink":"https://fanjames.github.io/blog/2018/07/15/在浏览器中显示视频流/","excerpt":"前阵子在捣鼓人脸识别的东西，一直都是采用OpenCV窗口显示摄像头视频，后来想把程序做成web应用，就要考虑如何把视频流嵌入到浏览器中，找了一圈只找到一种能在Flask中使用的方法。这种方法采用动态JPEG（Motion JPEG）的方式采集视频帧，然后将编码成JPEG图片传到浏览器，就这样动态视频。这种方式实现起来比较简单，并且大多数浏览器（Firefox、Chrome、Safari）都原生支持M-JPEG格式，但是对于事件的支持好像不太友好，Miguel Grinberg的博客中提到可以采用coroutine的方式，后面找时间试一下。","text":"前阵子在捣鼓人脸识别的东西，一直都是采用OpenCV窗口显示摄像头视频，后来想把程序做成web应用，就要考虑如何把视频流嵌入到浏览器中，找了一圈只找到一种能在Flask中使用的方法。这种方法采用动态JPEG（Motion JPEG）的方式采集视频帧，然后将编码成JPEG图片传到浏览器，就这样动态视频。这种方式实现起来比较简单，并且大多数浏览器（Firefox、Chrome、Safari）都原生支持M-JPEG格式，但是对于事件的支持好像不太友好，Miguel Grinberg的博客中提到可以采用coroutine的方式，后面找时间试一下。 感慨一下，实践果然是非常锻炼人的，一个小问题往往牵扯到很多的细节，要想解决好又要去了解很多相关的技术原理。在一个没有专业分工的地方，所有的东西只能自己去解决，慢慢修炼成为一个全栈工程师，虽然不用样样精通，但必须至少在一个方面是专家，并且对其他方向有一定的了解。下面就记录一下在浏览器中嵌入视频流的解决方案。 维基百科对M-JPEG的介绍： M-JPEG只使用帧内压缩（区别于算法更复杂的帧间压缩），只单独的对某一帧进行压缩，而不考虑视频画面中不同帧之间的变化。因此压缩效率比较低，一般低于1:20，而使用了帧间压缩的现代视频压缩格式（如MPEG1、MPEG2和H.264/MPEG-4 AVC）一般能超过1:50。由于各帧直接是相互独立的，M-JPEG的编解码在对运算能力和内存的要求较低。 由于M-JPEG是纯粹的帧内压缩，每帧画面的质量只与编码率和画面的空域复杂度有关。包含大面积平滑变化或者单色区域的帧压缩效果较好，而包含复杂纹理、细线条（如文字）的区域容易产生由于离散余弦变换产生的噪声。M-JPEG的压缩效果与视频的时域复杂度无关。 TensorFlow London 14: Ben Hall &#x27;Machine Learning Workloads with Kubernetes and Kubeflow&#x27; from Seldon multipart视频流的content type必须是multipart/x-mixed-replace，如下所示，其中--frame作为标识符分隔每一帧图像。HTTP/1.1 200 OK Content-Type: multipart/x-mixed-replace; boundary=frame --frame Content-Type: image/jpeg &lt;jpeg data here&gt; --frame Content-Type: image/jpeg &lt;jpeg data here&gt; ... class BaseCamera(object): thread = None # background thread that reads frames from camera frame = None # current frame is stored here by background thread last_access = 0 # time of last client access to the camera event = CameraEvent() def __init__(self): \"\"\"Start the background camera thread if it isn't running yet.\"\"\" if BaseCamera.thread is None: BaseCamera.last_access = time.time() # start background frame thread BaseCamera.thread = threading.Thread(target=self._thread) BaseCamera.thread.start() # wait until frames are available while self.get_frame() is None: time.sleep(0) def get_frame(self): \"\"\"Return the current camera frame.\"\"\" BaseCamera.last_access = time.time() # wait for a signal from the camera thread BaseCamera.event.wait() BaseCamera.event.clear() return BaseCamera.frame @staticmethod def frames(): \"\"\"Generator that returns frames from the camera.\"\"\" raise RuntimeError('Must be implemented by subclasses.') @classmethod def _thread(cls): \"\"\"Camera background thread.\"\"\" print('Starting camera thread.') frames_iterator = cls.frames() for frame in frames_iterator: BaseCamera.frame = frame BaseCamera.event.set() # send signal to clients time.sleep(0) # if there hasn't been any clients asking for frames in # the last 10 seconds then stop the thread if time.time() - BaseCamera.last_access &gt; 10: frames_iterator.close() print('Stopping camera thread due to inactivity.') break BaseCamera.thread = None import cv2 from base_camera import BaseCamera class Camera(BaseCamera): video_source = 0 @staticmethod def set_video_source(source): Camera.video_source = source @staticmethod def frames(): camera = cv2.VideoCapture(Camera.video_source) if not camera.isOpened(): raise RuntimeError('Could not start camera.') while True: # read current frame _, img = camera.read() # encode as a jpeg image and return it yield cv2.imencode('.jpg', img)[1].tobytes() 参考 [1] https://blog.miguelgrinberg.com/post/flask-video-streaming-revisited[2] https://github.com/miguelgrinberg/flask-video-streaming","categories":[{"name":"编程","slug":"编程","permalink":"https://fanjames.github.io/blog/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://fanjames.github.io/blog/tags/Python/"}]},{"title":"最近一段时间的所见所想","slug":"最近一段时间的所见所想","date":"2018-07-04T03:15:57.000Z","updated":"2020-07-11T13:24:17.807Z","comments":true,"path":"2018/07/04/最近一段时间的所见所想/","link":"","permalink":"https://fanjames.github.io/blog/2018/07/04/最近一段时间的所见所想/","excerpt":"上届世界杯时正好在利物浦，至今转眼已经过去了4年。那时初到国外，到处都充满了新鲜感。那个时候只用专心课业，不用过多考虑将来。那个时候还年轻，可以有更多的选择。而现在，每天早上醒来就得面对单调重复的工作。","text":"上届世界杯时正好在利物浦，至今转眼已经过去了4年。那时初到国外，到处都充满了新鲜感。那个时候只用专心课业，不用过多考虑将来。那个时候还年轻，可以有更多的选择。而现在，每天早上醒来就得面对单调重复的工作。 俄罗斯世界杯已经开打20天，1/8之一决赛刚结束。虽然因为意大利没进到决赛圈，没看比赛的动力，但每天还是会看下每场比赛的比分，就把一些感想记录在这里好了。到了淘汰赛阶段，常规时间内的平局开始变多，要靠点球大战决出胜负，而且除了比利时打日本那场3:2，其他比赛的进球都不算多。可能是因为16强队伍的实力旗鼓相当，也可能是经过小组赛3轮的激烈对抗，休息时间又不够充分，队员的体能状况开始出现下滑。潘多拉雄鹰被高卢雄鸡灌了4个进球，可见防线有多烂。西班牙全场1114脚传球却未能攻破俄熊的大门，唯一的进球还是俄罗斯后卫的乌龙，点球大战两粒点球被扑出，足以说明思想包袱太重、脚感太差，所以最终倒在12码线上其实也并不意外。克罗地亚打丹麦那场比赛确实有点意外，按理说，克罗地亚实力应该在丹麦之上，但最后竟然拖到了点球大战，5:4险胜，以这种状态下场比赛打俄罗斯怕是凶多吉少。","categories":[],"tags":[{"name":"闲话","slug":"闲话","permalink":"https://fanjames.github.io/blog/tags/闲话/"}]},{"title":"GPU服务器配置的问题记录","slug":"GPU服务器配置的问题记录","date":"2018-06-30T04:47:20.000Z","updated":"2020-07-11T13:24:17.795Z","comments":true,"path":"2018/06/30/GPU服务器配置的问题记录/","link":"","permalink":"https://fanjames.github.io/blog/2018/06/30/GPU服务器配置的问题记录/","excerpt":"这几点一直在折腾GPU服务器，大问题倒也没有，就是小麻烦不断出现。为避免以后遇到类似问题又要重新搜索，干脆就记录在这里，以备不时之需。","text":"这几点一直在折腾GPU服务器，大问题倒也没有，就是小麻烦不断出现。为避免以后遇到类似问题又要重新搜索，干脆就记录在这里，以备不时之需。 显卡独立电源接线手上有两块公版1080ti和两台i7 6700、8G主机，但是因为电源的问题，闲置了一段时间。1080ti额定功率250W，峰值功率会达到300W，所以，考虑同时给两块显卡供电，电源功率要不小于600W。前天从某东上入手了海韵的650FX，比618的时候贵了不少，只能说不赶趟了。 电源到手后遇到的第一个问题就是，启动电源要有触发信号。一般情况下，电源装在机箱里，与主板连接，这时就不需要考虑触发信号的问题，直接开机就能使用。但是由于两台主机是HP的品牌机，主板是定制化的，与电源的接口不兼容。上网一查，原来短接电源M/B接口的两个针脚就可以无主机启动电源了。 还有一点必须特别注意的是：在用独立电源给显卡供电的时候，必须先打开电源，再开机，否则将启动主板的集显，独立显卡将不会工作。 两台GPU服务器能正常工作后就是安装显卡驱动、运行环境这些工作了。 安装显卡驱动1、安装编译环境：gcc、kernel-devel、kernel-headersyum -y install gcc kernel-devel \"kernel-devel-uname-r == $(uname -r)\" dkms 2、 修改/etc/modprobe.d/blacklist.conf文件，以阻止 nouveau 模块的加载。添加blacklist nouveau，注释掉blacklist nvidiafb（如果存在）, blacklist.conf不存在时，执行下面的脚本echo -e \"blacklist nouveau\\noptions nouveau modeset=0\" &gt; /etc/modprobe.d/blacklist.conf 3、重新建立initramfs image文件mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak dracut /boot/initramfs-$(uname -r).img $(uname -r) 4、添加 ELRepo 源:sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org sudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 直接安装最新版的驱动即可:sudo yum install nvidia-x11-drv nvidia-x11-drv-32bit 5、安装cuda和cudnn从 https://developer.nvidia.com/cuda-toolkit-archive 下载所需版本的cuda，直接安装sh cuda_9.0.176_384.81_linux-run # 添加环境变量 # 在 ~/.bashrc的最后面添加下面两行 export PATH=/usr/local/cuda-9.0/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:$LD_LIBRARY_PATH # 使生效 source ~/.bashrc 相应地，从 https://developer.nvidia.com/rdp/cudnn-archive 下载所需版本的cuDNN，解压，将解压后的文件移到对应的目录下即可。tar -xvzf cudnn-9.0-linux-x64-v7.0.tgz cp -P cuda/include/cudnn.h /usr/local/cuda-9.0/include cp -P cuda/lib64/libcudnn* /usr/local/cuda-9.0/lib64 chmod a+r /usr/local/cuda-9.0/include/cudnn.h /usr/local/cuda-9.0/lib64/libcudnn* 显卡风扇转速动态调节安装X server首先安装X server环境，这是系统中才有xinit命令。yum groupinstall 'X Window System' -y 在系统中使用以下命令即可关闭：systemctl set-default multi-user.target 如果需要启用X-Windows在命令行中运行以下命令即可：startx 启动guisystemctl start graphical.target GPU风扇动态调节脚本下载GitHub上的这个库(https://github.com/boris-dimitrov/set_gpu_fans_public)修改目录名sudo mv set_gpu_fans_public set-gpu-fans 创建一个符号链接，让系统知道这个代码在哪里：ln -sf ~/set-gpu-fans /home/set-gpu-fans 不知道是什么原因，原文章用的是tcsh执行，进入set-gpu-fans目录，执行sh ./cool_gpu &gt;&amp; controller.log &amp; tail -f controller.log 参考：https://www.leiphone.com/news/201707/z88LWb5adH1MzTAR.html Docker全局透明代理","categories":[{"name":"硬件","slug":"硬件","permalink":"https://fanjames.github.io/blog/categories/硬件/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://fanjames.github.io/blog/tags/机器学习/"},{"name":"硬件","slug":"硬件","permalink":"https://fanjames.github.io/blog/tags/硬件/"},{"name":"Docker","slug":"Docker","permalink":"https://fanjames.github.io/blog/tags/Docker/"}]},{"title":"腾讯AIOps技术方案","slug":"腾讯AIOPS技术方案","date":"2018-06-07T14:36:53.000Z","updated":"2020-07-11T13:24:17.811Z","comments":true,"path":"2018/06/07/腾讯AIOPS技术方案/","link":"","permalink":"https://fanjames.github.io/blog/2018/06/07/腾讯AIOPS技术方案/","excerpt":"智能运维机器人是基于企业IM工具的，它和用户的交互界面，就是IM工具的会话窗口。","text":"智能运维机器人是基于企业IM工具的，它和用户的交互界面，就是IM工具的会话窗口。我们定义会话有三种模式： 智能模式，这是默认的模式。智能模式下，会对用户输入的消息进行文本匹配，返回相应的匹配结果。 操作模式。操作模式不提供主动切换的入口，而是在智能模式下，当识别到用户的输入，是一种操作需求时，自动进入操作模式。而操作发起或取消后，又自动切换为默认的智能模式。 人工模式。人工模式是用户主动点击切换的。在人工模式下，用户所有输入直接透传给运维账号的值班人员。 以下是一条消息或一个事件的简单处理流程： 考虑到一些小细节，实际处理逻辑比这个更复杂。比如，怎么避免两个智能运维机器人账号相互“灌水”？怎么回应用户发送的纯表情？又比如一些体验问题。当FAQ库里找不到用户问题的回答时，我们会提供一个快捷菜单，列出一些常见的自助操作或文档。那么怎么设计快捷菜单的出现时机？ 作为智能客服的变种，对话系统是智能运维机器人的核心。上述流程图中，只是简单地写了调用对话系统获取结果。实际上，调用对话系统后的返回，会有几种情况。具体如下图所示： 上图其实透露了一点，我们的对话系统，技术选型并非是当前研究热点的生成式模型，而是基于检索的模型。这也是考虑到智能运维机器人的应用场景中，用户和智能运维机器人交互时，不是想找个人聊聊天放松一下，而是想得到一个权威解答。 所以，我们利用运维账号积累的用户高频问题和对应的标准化答案，构成了一个简单易编辑可扩展的知识库。对话系统的主要功能，就是把用户问题和知识库中的合适答案关联起来。下图就是对话系统的结构图。其中，多轮引擎和图谱引擎还在实现中。 我们的这一套技术框架里，对于用户的问题，会使用建有高效索引的检索系统先召回部分高分的答案，再进行精确的匹配和排序。这种“粗排”和“精排”两步走的方案，是很多信息检索系统（包括推荐系统）的标准范式。添加一个“粗排”的步骤，可以排除大部分无关的候选集，大大减少需要精确排序的候选集。在知识库的知识条目数很大的时候，耗时能够指数级地减少。 “粗排”过后，我们就可以对召回的那部分候选的知识库问答对做“精排”了。这个过程中，我们用到了两大类的匹配模型。 一类是传统的文本匹配模型。这些模型都没有用到深度学习，本质上就是判断用户问题和知识库中的问题（及部分答案信息）的相似度（两个文本串的相似）。根据匹配的语素单位分，可以基于字、基于词、基于N-gram的多粒度的匹配。在简单文本匹配方法里，有编辑距离和扎卡德系数等。在传统信息检索方法里，利用领域语料信息的检索方法，如TFIDF，已经有更好平滑方法的BM25。 另一类，就是神经网络分类模型。简单来说，这个模型是这样的： 在搜索引擎这类文本检索的场景，查询往往是几个关键字，但是待查询的文档却很长，不用担心查询的关键字和待查询文本没有交集。但是在问答的场景中，用户问题和知识库中的问题，很大概率没有任何一个相同词，但是仍然表达一个意思。 所以，我们借助词向量技术，将任何语素单位（字、词）表示成一个低维空间的连续变量，这样可以构建一个字词之间的有效距离空间，进而更加精确地去匹配两个文本的语义距离，而不是字面上的距离。我们将词向量技术同我们的监督任务本身在一个端对端网络中进行训练。 这种方法也是当前文本表示和文本匹配技术的标准范式。先将字词等语素单位通过词向量矩阵映射成连续向量，然后利用CNN/RNN等神经网络去提取文本词向量之上的高阶特征，再通过这些特征去构建一个分类任务。 在智能运维机器人场景里，就是对用户问题和一个个知识库问题做0/1分类，1表示这两个问题是同一个意思。由于词向量矩阵、CNN/RNN参数以及特征做分类的权重矩阵都是一个网络图里面的参数，可以联合起来训练，这样就给了网络更大的灵活性。 与文本表示的场景不一样，文本匹配的场景更依赖于两个句子的交互信息。而一维匹配模型分别去建模两个句子，然后对表示求距离的方式并不能很好地建模两个句子的交互信息。我们选择用二维匹配模型，在一开始就构建两个句子的联合表示，对这个联合表示去求特征，以得到更好的结果。 此外除了词向量的信息，句子中其它特征也可以编码成向量作为CNN/RNN的特征。比如句子里面的字词位置信息、两个句子相互重叠的位置、词的词性信息等信息。同时在自然语言处理领域的attention机制也是文本匹配的关键信息，让句子对特定的字词更加敏感，这也是符合人类认知的习惯，通过最显著的部分来抓住信息的关键。 所有的传统文本匹配模型得到的分数，和神经网络分类模型得到最后的分数，用一个回归模型组合起来，得到用户问题和知识库问题的匹配度，最后把匹配度在指定阈值之上的知识库问题和它的答案返回给用户。","categories":[{"name":"转载","slug":"转载","permalink":"https://fanjames.github.io/blog/categories/转载/"}],"tags":[{"name":"AIOps","slug":"AIOps","permalink":"https://fanjames.github.io/blog/tags/AIOps/"}]},{"title":"【转载】知识图谱的知识表示","slug":"知识图谱的知识表示","date":"2018-06-03T11:49:06.000Z","updated":"2020-07-11T13:24:17.811Z","comments":true,"path":"2018/06/03/知识图谱的知识表示/","link":"","permalink":"https://fanjames.github.io/blog/2018/06/03/知识图谱的知识表示/","excerpt":"知识表示（Knowledge Representation，KR，也译为知识表现）是如何将结构化数据组织，以便于机器处理和人的理解的方法。从结构推导出新的结构，这就是推理。传统上KR属于逻辑的分支，但在实践中我们会用很简单、可读、可维护的数据结构。","text":"知识表示（Knowledge Representation，KR，也译为知识表现）是如何将结构化数据组织，以便于机器处理和人的理解的方法。从结构推导出新的结构，这就是推理。传统上KR属于逻辑的分支，但在实践中我们会用很简单、可读、可维护的数据结构。 经典的教科书中的KR，主要关注的是如何方便机器处理。但是在现实的工程中，如何方便人的理解也是极为关键的。在工程实践中，人才是知识不能被处理好、不能快速交换、不能规模化的核心。 知识表现的瓶颈不在于机器处理能力的不足，而在于人的认知能力的不足。因此，我们在学习知识表现方法的时候，要始终牢记知识的可读性、可维护性要远远比它的表达力、计算速度重要。知识是为人阅读而设计的，只是偶尔被机器执行。 数据优先，逻辑靠边 作为工程师，我们时时刻刻把可行性放在心中。传统的知识图谱的KR，从逻辑和推理讲起，有一阶逻辑(first-order logic)和描述逻辑(description logic)，后来又有逻辑程序(logic program)和生成规则（Production Rule）。但是我反对从逻辑开始理解知识图谱。语义网和知识图谱是关于数据的，关于结构促进数据的流动，用结构化数据增进其他系统的自动化能力的。逻辑只是很小的一个插件。 语义网，或者现在的知识图谱，在应用中，核心问题不是“应该怎么样”，而是“不得不怎么样”。语义推理对数据质量的要求很高，在工程上成本就承受不了。现实的应用，只能逐步提高数据的质量，从数据清洗开始就要承担巨额的投入，然后做实体抽取，实体链接，对齐，消歧，关系抽取，对齐，词库提取，本体建模，这每一步都是海一样的银子砸进去。 然后在推理中，推理规则都需要人生成。现在机器生成规则的能力很弱，几乎不可用。仅仅是属性和直接关系的查找可以机器做，稍微复杂的长程关系都需要人来写。这在工程部署中有巨大的困难，因为这样的工程师很少，写出来的东西可维护性，性能，普适性都成问题。所以现实中的系统，很少有做推理的。即使是做推理，也很少是一阶逻辑推理，一般也就是if then else，命题逻辑。很多时候还要容忍数据中的噪声，和正则表达式等结合在一起用。所以学术派的推理机，一般都用不了。 所以我们会了解RDF和OWL，但是并不推荐使用这些W3C标准作为工程的选择。我们认为JSON和关系数据库是工程中成本较小的解决方案。在某些特定场合，图的表示也是合理的。这会在之后的“知识存储”的章节继续讨论。 知识表现的数据结构 在知识提取之后，如何表示知识？其实知识并不神秘，只是一些数据之间的关系。在计算机中的表示，就是数据结构。传统上，我们把那些能够导出新的关系的关系（比如“爸爸的爸爸是爷爷”，这里面“爸爸”和“爷爷”都是关系）看成知识。但是在目前的知识图谱实践中，并不会有严格的区分，我们把各种结构都可以看成广义的知识。 不过不是所有的数据结构我们会用知识工程的方法来处理，比如集合、哈希表、队列、堆栈、链表等等，一般丢给软件工程去处理。另一类特殊的结构，二维表，我们丢给数据工程去解决。当然数据工程和知识工程之间没有严格的界限，二维表和复杂知识结构表示之间也有交叉，暂留后述。 知识表现的数据结构，一般来说是那些“复杂”的结构，最常见的就是图（graph）和树（tree）。 知识表现的图，是“有类型的边”（typed edge），分析方法和一般的图论和社交关系图谱中分析的无类型的边很不相同。传统的Web结构只有“链接”这一种关系。在2000年代中，语义网试图给链接加上类型说明，如某人主页声明工作于某公司，这就有“工作”关系。这里，类型就是边的“元数据”（metadata）。后来，发现在应用中还需要给边，当然还有节点，添加更多的元数据，这就形成了有类型的边构成的图谱结构，上面每个边和每个节点都拥有元数据。 图的知识表现，演化出两个流派。一个是RDF图，一个是属性图（Property Graph）。RDF图是W3C的官方标准，得到了政府资金和一些大公司的大力支持，但是最终市场表现平平。属性图是草根自发的，最终得到了市场的认可，现在主要是中小企业、创业公司在用。RDF图是科学顶层设计出来的，属性图是工程实战中总结出来的。它们发展轨迹的不同也再次证明，好的架构一般是总结出来的，不是凭空设计出来的。 RDF图的基础是三元组，用URI命名节点和连接节点，有严格的语义，约束比较多。属性图没有严格的语义，可以比较自由地声明节点和边的属性。RDF的优势在于推理，但是三元组的组织使稍复杂的关系的表达很困难，具体后述。属性图不定义推理，但是可以通过查询语言（如Gremlin）来做模式（pattern）的查找和图上的遍历（traverse），可以实现特设的(ad-hoc)的推理。也待到图数据库部分细说。 用图表示知识，丰富的知识结构主要表现为图上的边，各种推理算法就是在图上推导出边的算法。在传统图论里，有可达性（reachability）推理，有大量的优化研究。一些基本的传递性的推理，如分类树（taxonomy），是可以转化为图可达性推理的。但是大量的其他类型的推理，没有成熟的工程系统和算法可用。现有的图数据库，都局限很大，工程上成本很高。 图表示的另一个问题是对混合表示不是很友好。因为知识提取的成本是很高的，所以现实的工程中我们很难一步到位生成纯结构化的数据表示，我们的数据往往是结构化和非结构化（主要是文本）混合的。其中结构化的比例，结构化的质量，可能是在应用的过程中逐步提升的。开始的时候可能文本的比例比较大。虽然RDF图和属性图上的节点都可以有文本属性，但是图的索引还是与文本索引大不同，在实际使用中需要依赖集成Lucene之类的全文检索引擎。由于文本不是“一等公民”，很多建模难以实现，比如在RDF里文本不能作为三元组的主语。 由于图表示很复杂，最广为接受的知识组织其实是树（taxonomy，hierarchy）。这是人的认知决定的。计算机发展这么多年，界面元素的组织，被广为接受的也只有树、列表、表格。那些看起来很复杂的知识库，其基础也都是树。 所以树形的JSON最终脱颖而出，不是偶然的。它符合人的认知，满足了结构化和非结构化混合表示的需要，兼容现有的工程实现。JSON表示被称为“文档”（document），2009年以来兴起了很多文档数据库（document database）。最近又有了PostgeSQL和OrientDB这样混合关系与文档的数据库，可以实现可读性好、工程兼容性好、表达力也还够用的知识表示。 JSON和YAML，易读知识的艺术 JSON是很简单的数据格式。JSON成为Web API的事实标准，部分实现了当初语义网的一些目标。但是几年前，我和一位语义网领域的知名教授聊到语义数据的表示问题，我提到了JSON，他表示没听说过。这让我很震惊，学术界何以对工业界数据表示的事实标准如此不关心呢？ 我们做研究，一定要从实践中来，到实践中去。实际的数据是什么样，用什么样的成本能获得这些数据，这都不是随便能假设的。JSON在和XML的竞争中胜利，基于JSON的REST服务框架在和基于XML的SOAP的竞争中胜利，不是偶然的。因为JSON和REST更符合人的认知的需要，生成他们的成本低，理解他们的成本低，工程师容易理解，最终就用起来了。所以现在XML和SOAP虽然是“国际标准”，但在Web上用的人很少，JSON和REST这些“野路子”一统天下。这和属性图数据库超越RDF数据库是一个道理。 在Python中使用JSON超级简单，JSON和Python的字典很像，可以转换。看官方文档即可 json库 掌握下面这些库会让你处理json和字典的时候更开心 attrdict a[‘foo’][‘bar’]可以写做a.foo.bar 或a[‘foo’].bar。可读/写属性，可递归访问属性，继承dict的各种方法 marisa-trie 超级节约内存的字典 DAWG 另一个超级节约内存的字典 orderedmultidict 多值有序字典 jsonpickle JSON持久化。支持更复杂数据的存储 jq 命令行上的json处理和查询 pjson 在命令行上彩色打印json jsonlint 格式化json jsawk json的awk，一个快速的命令上的查询工具 json-diff 比较两个json 以上都是良心推荐，经多年工程实战考验的趁手工具。掌握了这些即使学不好知识图谱，也可以成为不错的数据科学家 :D 还有一些高级的话题，json pointer， json schema， xml2json， csv2json，暂时不提。我们只需要知道，json的工具链极为丰富。很多时候我们处理数据，就是卡在这些“小”工具上。你要是用了RDF，就会在无数小地方上因为缺少这些小工具而痛苦。 最后要隆重推荐一下YAML：JSON的超集，有更简洁的语法 警告 Yaml可能有严重的世界观副作用，过敏者请谨慎使用。 YAML在我看来比JSON的可读性更好，更加Pythonic（因为其语法接近Python）。当然有人可能会不喜欢缩进，不过Python社区的智力一般比较高，不会有这种偏见。YAML里可以有节点之间的链接，因此可以表示图。此外yaml里可以写!注!释！我认为YAML是天然的最好的知识图谱表示语法。 PyYAML 是Python里的Yaml处理库。 不过Yaml解析的速度比json慢得多，大概只有1/10。但是我们要牢记，知识表示最重要的是对人的友好，不是对机器的友好。速度不是大的问题，大部分的知识库都不是特别大。 最后多说一句无关的话，很多语言都有可读性更好的类Python语法。下面是我收集的一个列表 语言 语法 yaml readable json coffeescript readable javascript RapydScript readable javascript groovy readable java markdown readable html RapydML readable html jade readable html template SASS,Stylus readable css Turtle readable RDF 有一本经典的编程书《The Art of Readable Code》。 我觉得同样的在知识表示里，我们应该追求“易读知识的艺术”。工程上，这是特别重要的一件事。 RDF和OWL 虽然在大部分的应用场景下我都不会推荐大家使用RDF和OWL，但了解一下它们还是很有必要的，当是打免疫针。当然这两个语言非常的复杂，官方文档打印出来有1000页厚，展开讲的话一个学期也讲不完。好在我们是工程师，只关心如何应用，不需要全面了解。 但基础的RDF是非常非常简单的，一页纸就能说清楚。RDF的基本单元是三元组（triple）。每个三元组是（主语 谓语 宾语）这样的元组 tuple。主谓宾的取值称为“资源”（Resource，也就是RDF里的R）。资源可以是一个网址（URI），一个字符串或数字（严格来讲都是带类型的字符串，称为literal），或者一个“空节点”（blank node）。主谓宾有一些限制，这里不细说，看后面提到的文档。 有两种特殊类型的资源。rdfs:Class代表类。rdf:Property代表二元关系。有一种特殊的关系叫rdf:type ，声明一个资源属于某一个类。 用RDF建模，就要把所有的数据结构分割为三元组。这对我们智人是很麻烦的事情，因为我们的认知里还会有定语、状语、补语，所以RDF提供了一些很麻烦的变通方法，例如reification。空节点也是一种方法。这些在实践中都会带来无穷无尽的烦恼。 一个三元组就是一个关系。在RDF里我们可以声明一些规则，从一些关系推导出另一些关系。这些规则我们称为“schema”，所以有了RDFS（RDF Schema）。这些规则用一些词汇（可以类比编程语言里的保留字，不过RDF里任何词汇都可以被重定义和扩展）表示，如subClassOf subPropertyOf domain range。 RDF里的推理规则有十几条，其中最常用的大概就是父类子类关系（subClassOf）。有了它就可以表示分类树，这种最常见的知识组织。后来在一些领域大家需要其他的一些推理规则，就又添加了几十条规则，例如要表达女儿都是女生、哥哥的哥哥还是哥哥、爸爸的爸爸是爷爷、每人只有一个亲爸爸，等等。这些规则被称为OWL，其中O代表Ontology（本体）。我们不必关心本体的哲学定义，只要知道它是一些数据和推理规则的集合就好了。 RDF和OWL都有严格的语义。一种叫模型论语义，是一种非常可怕的东西！它是一个高阶的语义，充斥着难懂的话，什么“映射”、“外延”、“解释”、“蕴涵” 之类。模型论语义是这样的使人快活，可是没有它，别人也便这么过。因为还有基于规则的语义；这是一种不完备的语义，因为有些推理可能不能100%得到模型论要求的结果。不过对于应用，这种不完备性基本无所谓。 RDF和OWL语义 http://blog.memect.cn/?p=871 我的两个ppt，讲解了RDF和OWL的模型论语义RDF和OWL的语法和基本使用，可以看官方的文档，还不算太难懂（英文） RDF 1.1 PrimerOWL 2 Primer各种语法里，优先推荐用 Turtle 语法，因为它简洁….得不像RDF Python里的rdflib包可以很方便处理RDF。推荐按rdflib的文档过一遍例子，加深对RDF的理解 这个2011年的综述，提到了各种RDF相关的Python包：RdfLib RdfAlchemy Fuxi ORDF Django-RDF Djubby Redland SuRF PySparql Sparta Oort Virtuoso pySesame pynappl HTTP4Store py4s 《Survey of Pythonic tools for RDF and Linked Data programming》 本文没包括的还有：rdfQuery PySWIP pyDatalog PyLog FLiP seth sparrow pymantic pyRDFa djubby pySPARQL。感兴趣的可以查查。我个人很喜欢pyDatalog，虽然不是RDF的推理机，但大部分RDF的可以完成的建模用pyDatalog也都能做，我觉得更自然些。 参考手册 语义网速查表OWL语法速查表 JSON-LD JSON-LD是RDF的JSON语法，其中LD代表Linked Data。它要解决的是RDF没有好的Web兼容语法问题。经典的RDF语法是XML的，不仅罗嗦和丑陋，也集成了XML“重”的一些特征，适合“企业级”（如今这个词差不多就是恐龙、笨拙、难用的代名词）应用。JSON-LD就是想提供一个和互联网事实标准更兼容的、“轻”的语法。 JSON-LD基本思想是（我个人的理解） 尽可能用对人友好的字符串来写作，而不是象在传统RDF里用难以理解的URI。为了解释字符串，就引入了@context，把字符串定义在一定的上下文下——这些上下文本身一般是URI。这是比XML domain更友好的设计，增强了可读性。 引入模块化组织，加强可读性和可维护性。传统的RDF的组织粒度太低，在三元组层面。JSON-LD把同一个主语的三元组组织在一个 {} 块下，方便写作和理解。块的主语可以用@id 属性声明。更高层面上它还提供了@graph 声明，你可以把它理解成一个子模块，模块里的内容可以共享一些元数据（比如上下文和注释）。JSON的官方文档：主页W3C标准 JSON-LD本身现在还没有普及起来。wikidata在用，谷歌的knowlege graph也在用，但大多数人还不知道。我个人认为这是个好东西，虽然难以预料未来能不能火起来。 JSON-LD体现了两个对人友好的特性：可读性和模块化。第一代的Web知识语言如RDF和OWL，可以类比为知识的“汇编语言”，对机器很友好，对人不友好。Turtle和JSON-LD这类第二代语言，开始“高级化”，注意了方便人来写作和阅读，注意了引入适应人的认知需要的模块。 模块化机制引入RDF，前后花了十多年的时间。我自己从2004-2010也参与了一些工作。可以说，中间大家都犯了很多错误，走到今天的知识图谱很不容易。今后大家肯定还会继续犯错误。但是如果大家能多想想人的需要，而不仅是机器的需要，可能会少犯些错误吧。 知识图谱的高级语言 最后再展开说说我对Web上知识表示的展望，基本基于我一篇老博文《语义网的高级语言》（2012-11-27） 在谈论语义网的时候，要和RDF路线区分开来。和一些人谈到语义网，他们说：“语义网死了”。如果从RDF的角度来说，是的——虽然W3C路线的支持者还不承认。但是这种观点，就如同计算机在只有机器语言，没有高级语言的时候就断言：“计算机死了”。 我大胆提出两个假设 RDF是一门低级语言，只适合机器使用——如同机器语言或者汇编语言 语义网需要一门高级语言，面向工程师（人），用来做大规模知识库的写作、重用 为什么说RDF是低级机器语言？ 用URL来寻址并不错。但是把精确寻址的任务交给人，要求人来设计URL，就如同在C编程中要求人对每个变量赋予内存地址。 RDF是一个“平坦”(flat)的语言，缺少内部的组织单元。有很多建议，引入诸如package, named graph这样的组织单元，但目前还没有达成共识或广泛采用。 RDF的语法，即使是Turtle，也没有可读性，理解和重用起来非常困难。 RDF缺少“宏”或者构造高层次组织的能力。其实SPARQL弥补了一点，就是graph pattern；一些语言如SPIN，把graph pattern作为可重用的单元，甚至可以生成新的数据。如果把这个能力作为RDF原生的能力就好了。 2010年RDF Working Group开预备会议。现在回来看，我那时的想法是错误的：为RDF引入更精确的语义，基于上下文(context)的组织和寻址，并不合适——虽然Pat Hayes后来很喜欢这个想法并在工作组内推一个类似的想法。 RDF的问题不是逻辑太少了，而是逻辑太多了。 知识工程的问题往往是太多考虑机器的需要，而不太考虑人的需要。而知识工程的瓶颈，又恰恰在人而不在机器。 三元组的问题在于模型的进化能力有限。想为一句话再加个时间戳？想表示Provenance？在RDF制定的早期，就提出了reification作为弥补。但是后来所有人都讨厌这个丑陋的补丁。后来陆续有四元组、五元组、六元组、Context、Named Graph等等各种其他的补丁。越搞越复杂，越来越没人懂。所以我认为，为知识表现专门开发一门语言没必要。特别是在RDF里Literals是二等公民（比如subject不允许是字符串！！），和它们真实的地位不相称。直接利用现有高级语言，如Python或Javascript，某个子集就好，不需要搞三元组。 RDF 1.1现在的几个努力方向：JSON语法，Named Graph, Turtle Syntax，这些都是好的。但是还不够。我甚至怀疑，在RDF框架内能不能达到易用性的目的。 因为从一开始，RDF就被设计成machine understandable语言。这本是好的，至少在1999年。但是一个缺少高级语言的情况，就好像编程语言的早期。结果就是知识工程的人月神话。 现在的情况也很象Web发明的时候：在Internet上，TCP/IP是面向机器的低级语言，而HTML和URL是面向人的高级语言。我觉得，现在有一个强烈的需要来设计一个Semantic Web的高级语言。 这样的高级语言要有什么特征呢？我觉得大体有这样几点 支持多粒度的知识/数据组织和重用 用字符串而不是URL来寻址。不追求addressing uniqueness, 而是probable and eventual addressing uniqueness 支持知识的分布式传输（按一定粒度） 使用目前主流程序员熟悉的语法形式。 尽可能少重新发明轮子——比如rdf:plainLiteral（我是作者之一）这样的字符串类型就没什么必要 支持结构化和非结构化数据的混合表达（RDF有Literal，不过，那个太局限了） 这个语言的文档不要提什么“语义”（有几个程序员关心SQL的语义？）,不要规定什么schema 把推理转化为图的操作或者编程语言内置的运算。在这之外的推理都先不考虑。 从一开始就设计成在cluster上能运行的语言 拜托，用程序员看的懂的语言和例子写文档。 其实这样的语言雏形的一些部分，在不同的技术平台上都已经自发出现了。语义维基，图数据库，新一代检索引擎，都包含了上述部分概念。有心人要做的，就是一个有机的组合。我想，在我写这一段的时候，大概已经有人开始做了。 我甚至觉得，都没有必要引入一个新的高级语言语法，就在现有的某种贴近RDF的编程语言里，做少量的增加就能实现目的。最理想的就是Python。为什么这么说？JSON本身就是Python的数据结构。而几乎所有的数据API都吃JSON。Python的类与属性定义与关系就是RDF的翻版。 其实更合适的是Lisp。但是Lisp对抽象思维要求太高，社区又太小。做面向Web的开发，为了工程经济性（人力上的），还是Python比较合适。","categories":[{"name":"转载","slug":"转载","permalink":"https://fanjames.github.io/blog/categories/转载/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://fanjames.github.io/blog/tags/转载/"},{"name":"知识图谱","slug":"知识图谱","permalink":"https://fanjames.github.io/blog/tags/知识图谱/"},{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://fanjames.github.io/blog/tags/knowledge-graph/"}]},{"title":"【转载】刘知远：面向大规模知识图谱的表示学习技术","slug":"刘知远：面向大规模知识图谱的表示学习技术","date":"2018-06-03T07:41:39.000Z","updated":"2020-07-11T13:24:17.795Z","comments":true,"path":"2018/06/03/刘知远：面向大规模知识图谱的表示学习技术/","link":"","permalink":"https://fanjames.github.io/blog/2018/06/03/刘知远：面向大规模知识图谱的表示学习技术/","excerpt":"原地址：http://www.cbdio.com/BigData/2016-03/03/content_4675344.htm 本讲座选自清华大学计算机科学与技术系刘知远老师于2016年1月19日在RONG V2.0 系列交流会——语言语音语义与大数据技术专场论坛上所做的题为《面向大规模知识图谱的表示学习技术》的演讲。","text":"原地址：http://www.cbdio.com/BigData/2016-03/03/content_4675344.htm 本讲座选自清华大学计算机科学与技术系刘知远老师于2016年1月19日在RONG V2.0 系列交流会——语言语音语义与大数据技术专场论坛上所做的题为《面向大规模知识图谱的表示学习技术》的演讲。 刘知远：大家好，我叫刘知远，来自计算机系。非常感谢前面李涓子老师、蔡老师讲了一些认知和知识图谱相关的知识，这样我就可以接着他们讲我今天的题目。我的题目是：表示学习跟大家耳熟能详的深度学习有密切的联系。 我们为什么要关注表示学习这个问题呢？我们可以看关于机器学习的一个重要公式，这个公式有三个部分组成，第一部分是关于数据或者问题的表示，在表示的基础上我们要去设计或者构建一个目标，也就是说我们要实现一个什么样的目标。在设定了目标之后，开始看怎么实现这个目标，这就是优化的过程。对于机器学习来讲，表示是这三个环节中最基础的部分，也是我们为什么会关注它的重要原因。对于自然语言处理和多媒体处理而言，所处理的数据是典型的无结构数据。为了让计算机更好地对这些数据进行智能处理，如何很好地表示它们是一个至关重要的问题。 什么是表示学习 什么是表示学习呢？在自然语言处理中，常用的表示方式是1-hot Representation，每一个词都可以表示成一个非常长的向量，这个向量的长度就是词汇的数量，例如汉语常用词有6000个，我们就把每个词表示成6000维的向量。每个词对应的向量中有一维设置为1，其他维度设置为0，这样很自然地就把人类语言中的所有词都独一无二地表示成一个向量，这样计算机就可以很好的区分某个词跟另外一个词是不一样的。这种方法非常简单，应用也非常广泛，例如搜索引擎中的百度、谷歌，当输入一个查询词，基本思路就是匹配哪些文档里面出现了这些查询词。其实背后本质就是把每一个词都表示成一个独一无二的符号。但是这种方法面临一个很大的问题，大家可以看到，其实很多的词互相之间有非常丰富的语义联系，比如说star和sun，一个是星星，一个是太阳，它们虽然是不同的词，但有密切的语义关联。但是计算机把它们表示成了两个独立的向量，忽略了它们之间的语义关系。这就是我们希望用表示学习解决的问题。 表示学习的基本思想是提出一种所谓的Distributed Representation，或者是Embedding，用一个低维的向量空间，把每个词都表示到空间里面的某一个位置。这样，我们就可以利用词和词之间在这个空间中的距离来衡量词与词之间的语义关系，这就是表示学习的基本目标。 表示学习的基础是什么 表示学习的基础是什么？我为什么能够做这件事情？其实刚才蔡老师讲到了，这与人脑有非常密切联系。人脑有什么样的特点？第一个特点就是，人脑中的信号都是通过生物电或化学电传递的，这是一个非常低速的过程。但是我们又知道，人脑与计算机相比，虽然信号速度很慢，但认知能力却非常强，比如我们人可以快速地识别一张图片中哪个部分是老虎，哪个部分是草坪等等。但是对于计算机来讲，要实现这种认知能力却非常难。第二个，与计算机相比，人脑是一个非常低功耗的装置。也就是说对于人脑来讲，我们每天只需要吃几顿饭就可以让人脑一天到晚一直工作，但是对于计算机来讲，一台普通计算机每天消耗的能量比人脑要多得多。因此，人脑的工作原理非常值得我们学习。那么，人脑有什么样重要的工作机制呢？ 我们现实世界是一个离散的世界，这个世界里面每个物体相互之间都是独立的，有比较明确的界限，因此可以称为离散的世界。但是人脑表示这些物体的时候，都是表示为很多神经元上抑制和激活的状态。也就是说，我们用神经元上不同的抑制和激活状态来表示不同的物体。因此，虽然现实世界是离散的世界，但是在人脑的认知世界中，都被表示到连续的空间中。从这个角度来看，我们刚才所说的那种低维向量表示，其中每一维都可以看成是人脑的神经元。 现实世界带有非常强的层次性，比如人有头、四肢和躯体，头又可以分成头发、眉毛、五官等等。在认知世界里面也会对应存在这种层次性，即神经网络的层次结构。现在非常流行的深度学习技术就是由于引入了“深度”的层次性结构，带来了很多任务性能的革命性提升。 所以我们来看，人脑的这两个特点，对应到表示学习的两个特点，这两个特点就是：第一，采用分布式表示来表征现实世界的对象，即采用连续的空间表示对象。第二，采用深度的多层神经网络实现对现实世界的层次性建模，这也是表示学习的重要思想。 NLP中的表示学习 可以说，表示学习有非常强的认知基础。而同时，对于自然语言处理而言，也有着非常重要的现实意义，主要体现在两个方面，第一个方面，大规模自然语言处理面临非常强的数据稀疏难题，传统方法无法很好解决。而通过构建低维向量表示空间，我们把所有对象映射到这个空间里面，就可以利用这个空间的连续性较好地处理数据稀疏问题。另外一个好处是，可以实现不同领域以及不同对象之间的知识迁移。在自然语言处理中，我们关心的对象非常多，从最基础的词到句子，到文档，以及知识，我们如何更好地计算它们之间的语义关联呢？比如说给你一个句子、一个文档，怎么判断他们之间的语义关系？对传统的自然语言处理而言，这是非常难的事情。通过将这些对象映射到统一的空间中，我们将能够非常容易地计算它们之间的语义关系。因此，我们认为对于自然语言处理来讲，表示学习是非常重要的技术，也是近年来自然语言处理领域非常关心的方向。深度学习技术则是这个方面的重要代表。今天由于时间关系，不可能介绍表示学习在自然语言处理所有方面的应用。这里将以知识表示学习为例，向大家简单介绍最新的进展。 知识图谱是一种特殊网络，其中每个节点代表现实世界中的实体，而节点间的边表示实体之间的关系。知识图谱一般用三元组形式组织知识，每个三元组包括一个头实体、一个尾实体以及它们之间的关系。这是知识图谱的基本表示形式。有两种代表性的知识图谱，一个是语言知识图谱WordNet，包含了英语中词与词之间的同义、反义、上下位等关系。Wordnet是自然语言处理常用的语言知识库。另外一种知识图谱Freebace是世界知识图谱，包含了现实世界中人、地点、机构等实体以及它们之间的关系，例如，乔布斯是苹果公司的创始人等。 知识图谱中的表示学习：TransE 传统的知识图谱表示方式是基于RDF的三元组，相当于把每一个实体和关系都表示成独一无二的符号。这种方法与one-hot representation类似无法很好地利用或计算实体之间的语义关系。例如，乔布斯和比尔盖茨都是IT里面非常有名的人物，但是在知识图谱中用两个独一无二的符号表示，因此无法很好地计算它们之间的语义关系。因此我们希望通过表示学习来解决这个问题。如果能做到这一点，将能够更好地利用知识图谱中的知识。 现在主要介绍知识表示学习的一个最简单也是最有效的方案，叫TransE。在这个模型中，每个实体和关系都表示成低维向量。那么如何怎么学习这些低维向量呢？我们需要设计一个学习目标，这个目标就是，给定任何一个三元组，我们都将中间的relation看成是从head到tail的一个翻译过程，也就是说把head的向量加上relation的向量，要让它尽可能地等于tail向量。在学习过程中，通过不断调整、更新实体和关系向量的取值，使这些等式尽可能实现。这里面会有非常多技术实现细节，这里面就不作太多讲解，大家如果感兴趣可以去阅读相关论文。 这些实体和关系的表示可以用来做什么呢？一个直观的应用就是Entity Prediction（实体预测）。就是说，如果给一个head entity，再给一个relation，那么可以利用刚才学到的向量表示，去预测它的tail entity可能是什么。思想非常简单，直接把h r，然后去找跟h r向量最相近的tail向量就可以了。实际上，我们也用这个任务来判断不同表示模型的效果。我们可以看到，以TransE为代表的翻译模型，需要学习的参数数量要小很多，但同时能够达到非常好的预测准确率。 这里举一些例子。首先，利用TransE学到的实体表示，我们可以很容易地计算出跟某个实体最相似的实体。大家可以看到，关于中国、奥巴马、苹果，通过TransE向量得到的相似实体能够非常好地反映这些实体的关联。 如果已知head entity和relation，我们可以用TransE模型判断对应的tail entity是什么。比如说与中国相邻的国家或者地区，可以看到比较靠前的实体均比较相关。比如说奥巴马曾经入学的学校，虽然前面的有些并不准确，但是基本上也都是大学或教育机构。 如果同时知道heat entity和tail entity，我们也可以用TransE模型判断它们之间的关系。例如奥巴马和哥伦比亚大学之间就是一个入学学校的关系。这表明 TransE能够得到比较好的预测效果。 刚才我们简单介绍了TransE很有意思的性能，但是TransE也有自身的缺陷，这里我们简单总结TransE面临的若干挑战，以及在这些方面的最新研究进展。 首先，很多情况下TransE关于$h - r = t$的假设其实本身并不符合实际。为什么呢？假如头实体是美国，关系是总统，而美国总统其实有非常多，我们拿出任意两个实体来，比如奥巴马和布什，这两个人都可以跟USA构成同样的关系。在这种情况下，对这两个三元组学习TransE模型，就会发现，它倾向于让奥巴马和布什在空间中变得非常接近。而这其实不太符合常理，因为奥巴马和布什虽然都是美国总统，但是在其他方面有千差万别。这其实就是涉及到复杂关系的处理问题，即所谓的1对N，N对1、N对N这些关系。刚才例子就是典型的1对N关系，就是一个USA可能会对应多个tail entity。为了解决TransE在处理复杂关系时的不足，研究者提出很多扩展模型，基本思想是，首先把实体按照关系进行映射，然后与该关系构建翻译等式。 TransH和TransR均为代表扩展模型之一，其中TransH由MSRA研究者提出，TransR由我们实验室提出。可以看到，TransE在实体预测任务能够达到47.1的准确率，而采用TransH和TransR，特别是TransR可以达到20%的提升。对于知识图谱复杂关系的处理，还有很多工作需要做。这里只是简介了一些初步尝试。 对于TransH和TransR的效果我们给出一些例子。比如对于《泰坦尼克号》电影，想看它的电影风格是什么，TransE得到的效果比TransH和TransR都要差一些。再如剑桥大学的杰出校友有哪些？我们可以看到对这种典型的1对N关系，TransR和TransH均做得更好一些。 文本与知识图谱的融合 人类知识除了在知识图谱中，更多地蕴藏在大量的互联网文本中。如何把文本信息与知识图谱信息结合起来，更好地实现知识表示，是一个重要的挑战问题。其实如何从文本中抽取知识，是自然语言处理的重要研究任务，其基本思想是寻找两个实体共同出现的文本，然后从这些文本中抽取特征，用来判断实体间的关系。 我们来看知识表示与文本结合的重要意义。通过上图可以发现，如果单独利用文本信息进行关系抽取，效果如蓝线所示。而如果将知识表示信息结合进来，效果会有明显跃迁。这说明，如果能够将文本和知识图谱信息有效融合在一起，将有助于表示学习等任务的性能提升。另外一个非常重要的挑战是，实体在知识图谱中还有丰富的描述信息，这些信息也是文本形式的，怎么把它融合进来呢？我们尝试了采用卷积神经网络对文本建模。由于时间关系就不作详细介绍，如果大家感兴趣可以私下交流。 总之，有非常多的知识是蕴藏在无结构的文本里面的，如何把无结构的文本和有结构的知识结合在一起，是非常重要的研究方向，也是不断扩充知识图谱的重要技术手段，值得深入研究。 知识图谱关系路径的表示学习 最后我想介绍的是，如何充分利用知识图谱中的关系路径进行表示学习。我们可以看到，任意两个实体之间的关系，其实跟它们之间的关系路径有非常强的联系。比如说《阿甘正传》的电影语言其实与导演的语言有密切联系。如何充分利用关系路径，对于知识表示学习有重要意义。 过去就有人利用关系路径判断两个实体之间的关系，取得了非常好的效果。我们现在想说，在知识表示学习中，不只考虑直接的关联关系，还应当考虑两个实体之间的关系路径。这里有个重要问题，任给两个实体，如何把它们之间的关系路径也表示成向量，这就涉及到组合语义问题。 我们提出利用相加、相乘、循环神经网络的形式来实现组合语义，利用关系路径中每个关系的表示，得到关系路径的表示。这样我们就得到一个扩展的TransE模型，把关系路径表示成向量，然后构建$h - r = t$等式。 可以看一下扩展版TransE的性能。通过这些表格我们可以看到，考虑关系路径的模型在实体预测有超过35%的提升，这个提升是非常显著的。而在关系预测上，也有10%的提升，这个提升也非常明显。 由于时间关系这里就只举一个例子。如果我们能够很好地考虑关系路径，任给两个关系，假如它们形成一个路径的话，我们可以得到这个路径对应的关系，比如说某个关系路径是：“出生地点”和“地点所在国家”，通过模型可以推测出这个路径对应着关系“国籍”。 以上就是我们今天着重介绍的，如何在知识表示学习中考虑复杂关系，如何把文本和知识图谱信息相结合，以及如何考虑关系路径等等。当然，知识图谱的表示学习还有非常多值得研究的课题。 知识表示学习与深度学习在自然语言处理中的应用密切相关，最近两年正处在爆发期，今年自然语言处理会议的大部分论文都是关于深度学习的。这表明，表示学习是非常重要的研究方向。 最后想再强调一点，面向知识图谱的表示学习，对于更好地表示和利用知识图谱中的信息具有非常重要的意义。 这个方向仍然处于探索阶段，有非常多的工作值得去做。其有很多开放性的问题没有得到答案。比如人类认知的举一反三的能力，这代表了人的泛化能力以及抽象能力，目前深度学习和表示学习对此还做得不够好。2015年《科学》杂志上发表了一篇重要工作，就探索了只给一个样例来学习分类的问题，这对于人来讲很容易，但是对于机器则很难做到，特别是深度学习在这方面的能力非常差。实际上，深度学习领域在2014年发布过一个非常有名的成果，能够利用大规模无标注的图片自动学习和识别猫脸。其实这个过程有非常多的限制，包括使用了非常大量的猫的图片，而且都是标准的正脸。采用非常规范的数据学习得到猫脸，与人脑相比没什么了不起，因为人脑根本不需要这么多图片才能学到猫的样子。人只需要根据有限个样例，就能总结出猫的特点。这是深度学习和表示学习需要继续努力的方向。 在知识表示学习方面，我们做了一些工作，把常用的算法模型代码都开源在了网上。我们也发表了一些论文，都列在这儿，如果感兴趣欢迎浏览。","categories":[{"name":"转载","slug":"转载","permalink":"https://fanjames.github.io/blog/categories/转载/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://fanjames.github.io/blog/tags/转载/"},{"name":"知识图谱","slug":"知识图谱","permalink":"https://fanjames.github.io/blog/tags/知识图谱/"},{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://fanjames.github.io/blog/tags/knowledge-graph/"}]},{"title":"【转载】打造个性超赞博客Hexo+NexT+GithubPages的超深度优化","slug":"【转载】打造个性超赞博客Hexo-NexT-GithubPages的超深度优化","date":"2018-05-05T11:32:06.000Z","updated":"2020-07-11T13:24:17.795Z","comments":true,"path":"2018/05/05/【转载】打造个性超赞博客Hexo-NexT-GithubPages的超深度优化/","link":"","permalink":"https://fanjames.github.io/blog/2018/05/05/【转载】打造个性超赞博客Hexo-NexT-GithubPages的超深度优化/","excerpt":"","text":"https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html","categories":[{"name":"转载","slug":"转载","permalink":"https://fanjames.github.io/blog/categories/转载/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://fanjames.github.io/blog/tags/转载/"}]},{"title":"知识图谱概览","slug":"知识图谱概览","date":"2018-05-05T06:14:11.000Z","updated":"2020-07-11T13:24:17.807Z","comments":true,"path":"2018/05/05/知识图谱概览/","link":"","permalink":"https://fanjames.github.io/blog/2018/05/05/知识图谱概览/","excerpt":"知识图谱（Knowledge Graph）于2012年5月17日被Google正式提出，其初衷是为了提高搜索引擎的能力，增强用户的搜索质量以及搜索体验。目前，随着智能信息服务应用的不断发展，知识图谱已被广泛应用于智能搜索、智能问答、个性化推荐等领域。","text":"知识图谱（Knowledge Graph）于2012年5月17日被Google正式提出，其初衷是为了提高搜索引擎的能力，增强用户的搜索质量以及搜索体验。目前，随着智能信息服务应用的不断发展，知识图谱已被广泛应用于智能搜索、智能问答、个性化推荐等领域。 知识图谱是对物理世界的一种符号表达，其本身是一个具有属性的实体通过关系链接而成的网状知识库，从图的角度来看，知识图谱本质上是一种概念网络，其中的节点表示物理世界中的实体（或概念），而实体之间的各种语义关系则构成网络中的边。知识图谱能够改变现有的信息检索方式，一方面通过推理实现概念检索；另一方面以图形化方式向用户展示经过分类整理的结构化知识，从而使人们从人工过滤数据寻找答案的模式中解脱出来。 自从知识图谱被首次提出以来，知识图谱技术成为研究热点，国内多家公司相继发布各自的知识图谱产品，如百度的“知心”、搜狗的“知立方”。2017年7月20日，国务院发布《新一代人工智能发展规划》，其中“跨媒体分析推理技术”是八大关键共性技术之一，这一技术“重点突破跨媒体统一表征、关联理解与知识挖掘、知识图谱构建与学习、知识演化与推理、智能描述与生成等技术，实现跨媒体知识表征、分析、挖掘、推理、演化和利用，构建分析推理引擎”。知识图谱已经成为国家重点研究的技术领域之一，国家电网公司也在知识图谱技术上投入研发力量，构建电力领域的第一张“图谱”。目前，2018年国网科技项目“基于知识图谱的电网全业务统一数据模型关键技术及应用研究”由浙江公司牵头，联合安徽公司、南瑞集团和西安交通大学三家单位开展研究工作，目标是在全业务统一数据中心的数据仓库与数据集市之间构建业务数据知识图谱，建立起语义连接，实现跨业务数据贯通，降低人力成本，减少资源消耗。 在本专题中，我们将从实际构建知识图谱的角度详细介绍知识图谱的架构、构建的技术方法和自动更新维护的方法，最后介绍阿里公司在知识图谱应用中的实践经验。 知识图谱的架构 知识图谱的架构，包括知识图谱自身的逻辑结构以及构建知识图谱所采用的技术（体系）结构。知识图谱的逻辑结构分为两个层次：数据层和模式层。 在知识图谱的数据层，知识以事实（fact）为单位存储在图数据库。如果以『实体-关系-实体』或者『实体-属性-值』三元组作为事实的基本表达方式，则存储在图数据库中的所有数据将构成庞大的实体关系网络，形成知识的图谱。 模式层在数据层之上，是知识图谱的核心，在模式层存储的是经过提炼的知识，通常采用本体库来管理知识图谱的模式层，借助本体库对公理、规则和约束条件的支持能力来规范实体、关系以及实体的类型和属性等对象之间的联系。本体库在知识图谱中的地位相当于知识库的模具，拥有本体库的知识库冗余知识较少。 知识图谱的构建过程是从原始数据出发，采用一系列自动或半自动的技术手段，从原始数据中提取出知识要素（即事实），并将其存入知识库的数据层和模式层的过程。这是一个迭代更新的过程，如下图所示，根据知识获取的逻辑，每一轮迭代包含三个阶段：信息抽取、知识融合以及知识加工。 如何构建知识图谱 知识图谱的构建主要有自顶向下(Top-Down)和向底向上(Bottom-Up)两种方法。所谓自顶向下的方法是指首先为知识图谱定义数据模式(即为其定义本体)，在定义本体的过程中，首先从最顶层的概念开始，然后逐步进行细化，形成结构良好的分类学层次结构；在定义好数据模式后，再把实体一个个往概念中添加。自底向上的方法则刚好相反，首先从实体开始，对实体进行归纳组织，形成底层的概念，然后逐步往上抽象，形成上层的概念。两种方法在具体的构建过程中通常都不是从零开始的，前者可以利用一些现有的结构化的知识库，有利于抽取新的实例，可保证抽取质量，而后者则可以从开放链接数据或在线百科中得到很多实体，能发现新的模式。目前，大多数知识图谱都采用自底向上的方式进行构建，其中最典型就是Google的Knowledge Vault。 采用自底向上的方式构建知识图谱的过程是一个迭代更新的过程，每一轮更新包括3个步骤： 信息抽取，即从各种类型的数据源中提取出实体（概念）、属性以及实体捡的相互关系，在此基础上形成本体化的知识表达 知识融合，在获得新知识后，需要对其进行整合，以消除矛盾和歧义，比如某些实体可能有多种表达，某个特定称谓也许对应于多个不同的实体等 知识加工，对于经过融合的新知识，需要经过质量评估之后（部分需要人工参与甄别），才能将合格的部分加入到知识库中，以确保知识库的质量，新增数据之后，可以进行知识推理、拓展现有知识、得到新知识。 信息抽取 信息抽取是知识图谱构建的第一步，其中的关键问题是如何从异构数据源中自动抽取信息得到候选知识单元。信息抽取是一种自动化地从半结构化和无结构数据中抽取实体、关系以及实体属性等结构化信息的技术。涉及的关键技术包括：命名实体识别、关系抽取和属性抽取。 命名实体识别 命名实体识别（named entity recognition，NER）也称实体抽取，是指从文本数据集中自动识别出命名实体。实体抽取的质量（准确率和召回率）对后续的知识获取效率和质量影响极大，因此是信息抽取中最为基础和关键的部分。2012年Ling等人归纳出112种实体类别，并基于条件随机场CRF进行实体边界识别，最后采用自适应感知机算法实现了对实体的自动分类，取得了不错的效果。 但是随着互联网中内容的动态变化，采用人工预定义实体分类体系的方式已经很难适应时代的需求，因此提出了面向开放域的实体识别和分类研究。 在面向开放域的实体识别和分类研究中，不需要（也不可能）为每个领域或者每个实体类别建立单独的语料库作为训练集。因此，该领域面临的主要挑战是如何从给定的少量实体实例中自动发现具有区分力的模型。 一种思路是根据已知的实体实例进行特征建模，利用该模型处理海量数据集得到新的命名实体列表，然后针对新实体建模，迭代地生成实体标注语料库。另一种思路是利用搜索引擎的服务器日志，事先并不给出实体分类等信息，而是基于实体的语义特征从搜索日志中识别出命名实体，然后采用聚类算法对识别出的实体对象进行聚类。 关系抽取 文本语料经过实体抽取，得到的是一系列离散的命名实体，为了得到语义信息，还需要从相关的语料中提取出实体之间的关联关系，通过关联关系将实体联系起来，才能够形成网状的知识结构，研究关系抽取技术的目的，就是解决如何从文本语料中抽取实体间的关系这一基本问题。 早期的关系抽取研究方法主要是通过人工构造语法和语义规则。随后，出现了大量基于特征向量或者核函数的有监督学习方法，关系抽取的准确性也不断提高。但以上研究成果的共同特点是需要预先定义实体关系类型，如雇佣关系、整体部分关系以及位置关系等。 与之相对的，Banko等人提出了面向开放域的信息抽取方法框架，并发布了基于自监督学习方式的开放信息抽取原型系统TextRunner，该系统采用少量人工标记数据作为训练集，据此得到一个实体关系分类模型，再依据该模型对开放数据进行分类，依据分类结果训练朴素贝叶斯模型来识别『实体-关系-实体』三元组，经过大规模真实数据测试，取得了显著优于同时期其他方法的结果。 TextRunner系统中错误的部分主要是一些无意义或者不和逻辑的实体关系三元组，据此引入语法限制条件和字典约束，采用先识别关系指示词，然后再对实体进行识别的策略，有效提高了关系识别准确率。 属性抽取 属性抽取的目标是从不同信息源中采集特定实体的属性信息。例如针对某个公众人物，可以从网络公开信息中得到其昵称、生日、国籍、教育背景等信息。属性抽取技术能够从多种数据来源中汇集这些信息，实现对实体属性的完整勾画。 由于可以将实体的属性视为实体与属性值之间的一种名词性关系，因此也可以将属性抽取问题视为关系抽取问题。 百科类网站提供的半结构化数据是当前实体属性抽取研究的主要数据来源。但是还有大量的实体属性数据隐藏在非结构化的公开数据中。 一种解决方案是基于百科类网站的半结构化数据，通过自动抽取生成训练语料，用于训练实体属性标注模型，然后将其应用于对非结构化数据的实体属性抽取；另一种方案是采用数据挖掘的方法直接从文本中挖掘实体属性与属性值之间的关系模式，据此实现对属性名和属性值在文本中的定位。这种方法的基本假设是属性名和属性值之间在位置上有关联关系，事实上在真实语言环境中，许多实体属性值附近都存在一些用于限制和界定该属性值含义的关键词（属性名），在自然语言处理技术中将这类属性称为有名属性，因此可以利用这些关键字来定位有名属性的属性值。 知识融合通过信息抽取，实现了从非结构化和半结构化数据中获取实体、关系以及实体属性信息的目标，然而，这些结果中可能包含大量的冗余和错误信息，数据之间的关系也是扁平化的，缺乏层次性和逻辑性，因此有必要对其进行清理和整合。知识融合包含两部分内容：实体链接和知识合并。 实体链接 实体链接（entity linking）是指对于从文本中抽取得到的实体对象，将其链接到知识库中对应的正确实体对象的操作。 实体链接的一般流程是： 从文本中通过实体抽取得到实体指称项进行实体消歧和共指消解，判断知识库中的同名实体与之是否代表不同的含义，以及知识库中是否存在其他命名实体与之表示相同的含义。在确认知识库中对应正确实体对象之后，将该实体指称链接到知识库中对应实体。 实体消歧 实体消歧是专门用于解决同名实体产生歧义问题的技术，通过实体消歧，就可以根据当前的语境，准确建立实体链接，实体消歧主要采用聚类法。其实也可以看做基于上下文的分类问题，类似于词性消歧和词义消歧。 共指消解技术主要用于解决多个指称对应同一实体对象的问题。在一次会话中，多个指称可能指向的是同一实体对象。利用共指消解技术，可以将这些指称项关联（合并）到正确的实体对象，由于该问题在信息检索和自然语言处理等领域具有特殊的重要性，吸引了大量的研究努力。共指消解还有一些其他的名字，比如对象对齐、实体匹配和实体同义。 知识合并 在构建知识图谱时，可以从第三方知识库产品或已有结构化数据获取知识输入。常见的知识合并需求有两个，一个是合并外部知识库，另一个是合并关系数据库。将外部知识库融合到本地知识库需要处理两个层面的问题： 数据层的融合，包括实体的指称、属性、关系以及所属类别等，主要的问题是如何避免实例以及关系的冲突问题，造成不必要的冗余； 通过模式层的融合，将新得到的本体融入已有的本体库中。 然后是合并关系数据库，在知识图谱构建过程中，一个重要的高质量知识来源是企业或者机构自己的关系数据库。为了将这些结构化的历史数据融入到知识图谱中，可以采用资源描述框架（RDF）作为数据模型。业界和学术界将这一数据转换过程形象地称为RDB2RDF，其实质就是将关系数据库的数据换成RDF的三元组数据。 知识加工 通过信息抽取，可以从原始语料中提取出实体、关系与属性等知识要素，再经过知识融合，可以消除实体指称项与实体对象之间的歧义，得到一系列基本的事实表达。然而事实本身并不等于知识，要想最终获得结构化，网络化的知识体系，还需要经历知识加工的过程。知识加工主要包括3方面内容：本体构建、知识推理和质量评估。 本体构建 本体（ontology）是对概念进行建模的规范，是描述客观世界的抽象模型，以形式化的方式对概念及其之间的联系给出明确定义。本体最大的特点在于它是共享的，本体反映的知识是一种明确定义的共识。 本体是同一领域内的不同主体之间进行交流的语义基础。本体是树状结构，相邻层次的节点（概念）之间有严格的『IsA』关系。在知识图谱中，本体位于模式层，用于描述概念层次体系，是知识库中知识的概念模板。 本体可以采用人工编辑的方式手动构建（借助本体编辑软件），也可以以数据驱动的自动化方式构建本体，其包含3个阶段：实体并列关系相似度计算、实体上下位关系抽取以及本体的生成。 实体并列关系相似度适用于考察任意给定的两个实体在多大程度上属于同一概念分类的指标测度，相似度越高，表明这2个实体越有可能属于同一语义类别。所谓并列关系，是相对于纵向的概念隶属关系而言的。 实体上下位关系抽取是用于确定概念之间的隶属（IsA）关系，这种关系也称为上下位关系。 本体生成阶段的主要任务是对各层次得到的概念进行聚类，并对其进行语义类的标定（为该类的中的实体指定1个或多个公共上位词）。 当前主流的实体并列关系相似度计算方法有两种：模式匹配法和分布相似度。其中，模式匹配法采用预先定义实体对模式的方法，通过模式匹配取得给定关键字组合在同一语料单位中共同出现的频率，据此计算实体对之间的相似度。分布相似度方法的前提假设是：在相似的上下文管径中频繁出现的实体之间具有语义上的相似性。 实体上下位关系抽取是该领域的研究重点，主要的研究方法是基于语法模式（如Hearst模式）抽取IsA实体对。也有方法利用概率模型判定IsA关系和区分上下位词，通常会借助百科类网站提供的概念分类知识来帮助训练模型，以提高算法精度。 知识推理 知识推理是指从知识库中已有的实体关系数据出发，进行计算机推理，建立实体间的新关联，从而拓展和丰富知识网络。知识推理是知识图谱构建的重要手段和关键环节，通过知识推理，能够从现有知识中发现新的知识。 知识推理的对象也并不局限于实体间的关系，也可以是实体的属性值，本体的概念层次关系等。知识的推理方法可以分为2大类：基于逻辑的推理和基于图的推理。 基于逻辑的推理主要包括一阶逻辑谓词、描述逻辑以及基于规则的推理。一阶谓词逻辑建立在命题的基础上，在一阶谓词逻辑中，命题被分解为个体和谓词两部分。个体是指可独立存在的客体，可以是一个具体的事物，也可以是一个抽象的概念。谓词是用来刻画个体性质及事物关系的词。比如（A，friend，B）就是表达个体A和B关系的谓词。 对于复杂的实体关系，可以采用描述逻辑进行推理。描述逻辑（description logic）是一种基于对象的知识表示的形式化工具，是一阶谓词逻辑的子集，它是本体语言推理的重要设计基础。 基于规则的推理可以利用专门的规则语言，如SWRL（semantic web rule language）。基于图的推理方法主要基于神经网络模型或Path Ranking算法。Path Ranking算法的基本思想是将知识图谱视为图（以实体为节点，以关系或属性为边），从源节点开始，在图上执行随机游走，如果能够通过一个路径到达目标节点，则推测源和目的节点可能存在关系。 质量评估 质量评估也是知识库构建技术的重要组成部分。其意义在于：可以对知识的可信度进行量化，通过舍弃置信度较低的知识，可以保障知识库的质量。 通用知识图谱和行业知识图谱构建的区别 通用知识图谱和行业知识图谱的区别主要体现在覆盖面和使用方式上，这些区别也在一定程度上决定了两类知识图谱构建方法的不同。由于通用知识图谱在覆盖面方面要求高，因此强调更多的是实体，通常以自底向上的方式来构建;而行业知识图谱同时也注重概念之间的体系结构，因此在构建时通常会使用自顶向下和自底向上两种方式相结合的方式。 另一方面，由于行业知识图谱的专业性要求更高，所以通常需要使用特定的行业数据来源；因此，行业知识图谱在构建时，通常以结构化的关系数据库中热信息为起点，进而扩展到非结构化数据。 对于行业知识图谱的构建，行业的内部结构化数据以及一些开放的行业知识库或行业垂直网站会起非常关键的作用。这些行业数据源由于与行业业务结合紧密，因此通常具有如下优点： （1）具备良好的行业覆盖面和行业深度，行业数据由于描述目标的专一性，通常在行业内部的覆盖面方面会比较广，通常包含所描述行业的大多数信息，例如IMDB是互联网的数据集中拥有最全电影信息的网站。 （2）可靠性高：对于行业的内部结构化数据，通常情况下用于支撑企业本身的业务，因此可靠性非常高;对于开放的行业知识库数据，有些是企业的结构数据经过一定形式的转化发布到网上的，而有些则是经过行业专业人员的编辑和审核后发布到网上的，因此，可靠性也可以得到保证。 （3）结构性强：对于内部结构化数据，绝大多数是通过关系数据库进行存储的；而对于开放的行业知识库，通常是以网页的形式使用同样的模板生成的，因而结构基本相同，解析非常方便。 因此，在进行行业知识图谱构建时，会优先考虑使用行业中的内部结构化数据和开放的行业知识库。 如何维护知识图谱 知识图谱的目标是构建一个能够刻画现实世界的知识库，为自动问答、信息检索等应用提供支撑。因此，对知识的持久化存储并提供对目标知识的高效检索是合格的知识图谱必须具备的基本功能。 知识图谱的存储 按照存储方式的不同，知识图谱的存储可以分为基于表结构的存储和基于图结构的存储。基于表结构的存储利用二维的数据表对知识图谱中的数据进行存储，通常包括：三元组表、类型表、关系数据库等；基于图结构的存储利用图数据库对知识图谱中的数据进行存储。下面将分别介绍这几种存储方式的优缺点。 三元组表 基于三元组表的存储方式的优点是简单直接，易于理解；然而缺点也非常明显，主要有以下两点： （1）整个知识图谱都存储在一张表中，导致单表的规模太大。对大表进行查询、插入、删除、修改等操作的开销很大，这将导致知识图谱的实用性大打折扣。 （2）复杂查询在这种存储结构上的开销巨大。由于数据表只包括三个字段，因此复杂的查询只能拆分成若干简单查询的复合操作，大大降低了查询的效率。例如，查询“佩佩的身高和性别是什么？”需要拆分为“佩佩的身高是多少？”和“佩佩的性别是什么？” 类型表 类型表为每种类型构建一张表，同一类型的实例存放在相同的表中。表的每一列表示该类实体的一个属性，每一行存储该类实体的一个实例。 类型表克服了三元组表面临的单表过大和结构简单的问题，但是也有明显的不足之处： （1）由于数据表是和具体类型对应的，不同的数据表具有不同的结构，因此在查询之前必须知道目标对象的类型才能确定查找的数据表。 （2）当查询涉及到不同类型的实体时，需要进行多表的连接，这一操作开销巨大，限制了知识图谱对复杂查询的处理能力。 （3）知识图谱通常包含丰富的实体类型，因此需要创建大量的数据表，并且这些数据表之间又具有复杂的关系，这为数据的管理增加了很大的难度。 关系数据库 关系数据库以二维表结构对数据进行组织和存储，如果选择关系数据库作为知识图谱的存储引擎，那么对知识图谱的所有操作都需要转换为SQL语句才能执行。 图数据库 图数据库基于有向图，其理论基础是图论。知识图谱将实体看做节点，关系看做带有标签的边，那么知识图谱的数据很自然地满足图模型结构。节点、边和属性是图数据库的核心概念。 节点：节点用于表示实体、事件等对象，可以类比于关系数据库中的记录或数据表中的行数据。例如人物、地点、电影等都可以作为图中的节点。 边：边是指图中连接节点的有向线条，用于表示不同节点之间的关系。例如人物节点之间的夫妻关系、同事关系等都可以作为图中的边。 属性：属性用于描述节点或者边的特性。例如人物的姓名、夫妻关系的起止时间等都是属性。 下图是DB-Engines上最新一期（截至2018年3月）的图数据库得分排名，从中可以看出Neo4j在整个图存储领域里占据着NO.1的地位。 Neo4j：是一个开源的图数据库系统，它将结构化的数据存储在图上而不是表中。Neo4j基于Java实现，它是一个具备完全事务特性的高性能数据库，具有成熟数据库的所有特性。Neo4j是一个本地数据库（又称基于文件的数据库），这意味着不需要启动数据库服务器，应用程序不用通过网络访问数据库服务，而是直接在本地对其进行操作，因此访问速度快。因其开源、高性能、轻量级等优势，Neo4j 受到越来越多的关注。 OrientDB：是一个开源的文档-图混合数据库，兼具图数据库对数据强大的表示及组织能力和文档数据库的灵活性及很好的可扩展性。OrientDB具有多种模式可选，包括全模式、无模式和混合模式。全模式要求数据库中的所有类别都必须有严格的模式，所有字段都强制约束；无模式则相反，不需要为类别定义模式，存储的数据记录可以有任意的字段；混合模式则允许为类别定义若干字段，同时支持自定义字段。该数据库同样是本地的，支持许多数据库的高级特性，如事务、快速索引、SQL查询等。 HyperGraphDB：是开源的存储系统，并依托于BerkeleyDB数据库。和上述图数据库相比，HyperGraphDB最大的特点在于HyperGraph，即超图。从数学角度讲，有向图的一条边只能指向一个节点，而超图则可以指向多个节点。实际上，HyperGraphDB在超图的基础上更进了一步，不仅允许一条边指向多个节点，还允许其指向其它边。如此以来，HyperGraphDB相较于其它图数据库具有更强大的表示能力。 InfiniteGraph：是一个基于Java语言开发的分布式图数据库系统，它的目标是构建“分布式的图形数据库”，已被美国国防部和美国中央情报局所采用。和MySQL等传统关系数据库类似，InfiniteGraph需要作为服务项目进行安装，应用程序只能通过访问数据库服务对数据库进行操作。InfiniteGraph借鉴了面向对象的概念，将图中的每个节点及每条边都看做一个对象。具体地，所有的节点都继承自基类BaseVertex，所有的边则都继承自基类BaseEdge。 InfoGrid：是一个开源的互联网图数据库，提供了很多额外的组件，可以很方便地构建基于图结构的网络应用。InfoGrid实际上是一个基于Java语言的开源项目集，其中InfoGrid图数据库项目是其核心，其它的项目包括InfoGrid存储项目、InfoGrid用户接口项目等。 和成熟的关系数据库相比，图数据库的发展较晚，相关的标准及技术尚不完善，在实际使用中可能会遇到一些棘手的问题，因此在选用数据库时除了需要考虑数据库本身的特性、性能等因素以外，还需要考虑数据库的易用性、技术文档的完整性等因素。 知识图谱的数据更新 知识图谱的构建并非一促而就，它是一个不断改进和优化的过程。当数据源有更新或学习的方法有更新时，不可避免地要对知识图谱进行更新。知识图谱的更新主要分为两个层面的更新，数据模式层的更新和数据层的更新。 数据模式层的更新是指知识图谱本体中元素的变更，包括概念的增加、修改和删除，概念之间上下位关系的更新，以及概念属性的更新;其中最重要的更新是概念属性的更新，因为概念属性的更新操作会影响到所有直接和间接属性它的子概念和实体。因此，在通常情况下，知识图谱数据模式层的更新的处理会相当谨慎，尤其涉及数据模式的冲突和删除时;这些时候，数据模式的更新通常是在人工干预下进行的。 数据层的更新即指实体数据的更新，包括添加和删除实体，修改实体的基本信息和属性值。数据层的更新一般影响面小，因此通常以自动的方式完成。加入到知识图谱中的数据不是一成不变的，知识类型对应的实例往往动态变化。例如，搜索引擎公司利用其强大的计算保证图谱每天的更新在3个小时内完成，而实时的热点也能保证在事件发生6个小时内在搜索结果中反映出来。 为了保证其质量，知识图谱模式是由专业团队审核和维护的。以谷歌知识图谱为例，目前定义的类别数约为$10^3$~$10^4$量级。为了提高知识图谱的覆盖率，搜索引擎公司还通过自动化算法从各种数据源抽取新的类型信息（也包含关联的属性或关系信息）。这些信息并不是被马上加入到知识图谱模式中的。某一种类型若要长期保留，则要在发展到一定程度后，由专业的人员进行决策和命名，这样才能最终成为一种新的类型。 对于构建的知识图谱，除了需要内部专业团队进行审核和维护，还要依靠用户来帮助改善。具体来说，用户可以对搜索结果中展现的知识卡片所列出的实体相关的事实进行纠错。当很多用户都指出某个错误时，搜索引擎将采纳并修正。这种利用群体智慧的协同式知识编辑是对专业团队集中式管理的互补。 行业动态：阿里知识图谱 借助阿里知识图谱的建设，阿里电商平台管控从过去的“巡检”模式升级为发布端实时逐一检查。在海量的商品发布量的挑战下，最大可能地借助大数据、人工智能阻止坏人、问题商品进入阿里生态。同时面临问题商家实时的对弈、变异和恶意攻击等诸多挑战，知识图谱仍然保持着每天千万级别的拦截量，亿级别的全量智能审核次数，在滥发、侵权、合规、假货、经营范围等多个场景全面与问题卖家正面交锋，实时对弈。为了最大限度地保护知识产权，保护消费者权益，阿里对知识图谱推理引擎技术提出了智能化、自学习、毫秒级响应、可解释等更高地技术要求，实现良好的社会效益。 阿里巴巴生态里积累了海量的商品数据，这些宝贵的商品数据来自于淘宝、天猫、1688、AliExpress等多个市场，同时品牌商、行业运营、治理运营、消费者、国家机构、物流商等多种角色参与其中，贡献着这样一个庞大的商品库。无论是知识产权保护，还是提升消费者购物体验，实现商品数据的标准化（商品规范的统一和商品信息的确定性）, 以及与内外部数据之间的深度互联，意义都非常重大，阿里商品知识图谱承载着商品标准化这一基础性，根源性的工作。基于此才能知道哪些商品是同样一件产品，一个品牌是否被授权，品牌下的产品卖到了哪些市场。 阿里知识图谱以商品、标准产品、标准品牌、标准条码、标准分类为核心，利用实体识别、实体链指和语义分析技术，整合关联了例如舆情、百科、国家行业标准等9大类一级本体，包含了百亿级别的三元组，形成了巨大的知识网。 阿里知识图谱综合利用前沿的NLP、语义推理和深度学习等技术，打造全网商品智能服务体系，服务阿里生态中的各个角色。商品知识图谱广泛地应用于搜索、前端导购、平台治理、智能问答、品牌商运营等核心、创新业务。能够帮助品牌商透视全局数据，帮助平台治理运营发现问题商品，帮助行业基于确定的信息选品，做人货场匹配提高消费者购物体验等等。为新零售、国际化提供可靠的智能引擎。 引入机器学习算法搭建推理引擎 阿里设计了一套框架来实现知识表示和推理。此外，知识图谱实体、关系、词林（同义词、上下位词）、垂直知识图谱（例如地理位置图谱、材质图谱）、机器学习算法模型等都纳入进来做统一的描述。 按照不同场景，我们把推理分为：上下位和等价推理，不一致性推理，知识发现推理，本体概念推理等。例如： 1. 上下位和等价推理。检索父类时，通过上下位推理把子类的对象召回，同时利用等价推理（实体的同义词、变异词、同款模型等），扩大召回。 例如，为保护消费者我们需要拦截“产地为某核污染区域的食品”，推理引擎翻译为“找到产地为该区域，且属性项与“产地”同义，属性值是该区域下位实体的食品，以及与命中的食品是同款的食品”。 2. 不一致推理。在与问题卖家对弈过程中，我们需要对商品标题、属性、图片、商品资质、卖家资质中的品牌、材质、成分等基础信息，做一致性校验。比如说标题中的品牌是Nike而属性或者吊牌中品牌是Nake，如下图所示，左边描述了商品标题、属性、吊牌上的品牌信息是一致的，推理为一致。右边为吊牌和商品品牌不一致的商品，被推理引擎判断为有问题的商品。。 3. 知识发现推理。一致性推理的目的是确保信息的确定性，例如通过一致性推理我们能确保数据覆盖到的食品配料表正确。但消费者购物时很少看配料表那些繁杂的数字。消费者真正关心的是无糖、无盐等强感知的知识点。为了提高消费者购物体验，知识发现推理通过底层配料表数据和国家行业标准例如： 无糖：碳水化合物≤ 0.5g/100g（固体）或100mL（液体） 无盐：钠≤5mg/100g或100mL 我们可以把配料表数据转化为“无糖”、“无盐”等知识点。从而真正地把数据变成了知识。通过AB test验证，类似知识点在前端导购中极大地改善了消费者购物体验。 推理引擎背后技术框架 首先，推理引擎把自然语言通过语义解析(semantic parsing)转换为逻辑表达式(logical form)。语义解析采用了结合神经网络和符号逻辑执行的方式：自然语言经过句法、语法分析、NER、Entity Linking，被编码为分布式表示(distributed representation)，句子的分布式表示被进一步转义为逻辑表达式。 在分布式表示转换为逻辑表达式的过程中，首先面临表示和谓词逻辑操作之间映射的问题。把谓词当做动作，通过训练执行symbolic operation，类似neural programmer中利用attention机制选择合适的操作，即选择最有可能的谓词操作，最后根据分析的句法等把谓词操作拼接为可能的逻辑表达式， 再把逻辑表达式转换为查询等。过程示意如下图所示。 其次，逻辑表达式会触发后续的逻辑推理和图推理。逻辑表达式在设计过程中遵循以下几个原则：逻辑表达式接近人的自然语言，同时便于机器和人的理解。表达能力满足知识图谱数据、知识表示的要求。应该易于扩展，能够非常方便的增加新的类、实体和关系，能够支持多种逻辑语言和体系，如Datalog、OWL等，即这些语言及其背后的算法模块是可插拔的，通过可插拔的功能，推理引擎有能力描述不同的逻辑体系。 阿里知识图谱经过三年的建设，已经形成了巨大的知识图谱和海量的标准数据，引入了前沿的自然语言处理、知识表示和逻辑推理技术，在阿里巴巴新零售、国际化战略下发挥着越来越重要的作用。","categories":[{"name":"综述","slug":"综述","permalink":"https://fanjames.github.io/blog/categories/综述/"}],"tags":[{"name":"知识图谱","slug":"知识图谱","permalink":"https://fanjames.github.io/blog/tags/知识图谱/"},{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://fanjames.github.io/blog/tags/knowledge-graph/"}]}]}