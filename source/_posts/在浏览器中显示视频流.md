---
title: 在浏览器中显示视频流
date: 2018-07-15 18:07:09
tags: 
	 - Python
categories: 编程
---


　　前阵子在捣鼓人脸识别的东西，一直都是采用OpenCV窗口显示摄像头视频，后来想把程序做成web应用，就要考虑如何把视频流嵌入到浏览器中，找了一圈只找到一种能在Flask中使用的方法。这种方法采用动态JPEG（Motion JPEG）的方式采集视频帧，然后将编码成JPEG图片传到浏览器，就这样动态视频。这种方式实现起来比较简单，并且大多数浏览器（Firefox、Chrome、Safari）都原生支持M-JPEG格式，但是对于事件的支持好像不太友好，[Miguel Grinberg的博客](https://blog.miguelgrinberg.com/post/flask-video-streaming-revisited)中提到可以采用coroutine的方式，后面找时间试一下。
<!-- more -->

　　感慨一下，实践果然是非常锻炼人的，一个小问题往往牵扯到很多的细节，要想解决好又要去了解很多相关的技术原理。在一个没有专业分工的地方，所有的东西只能自己去解决，慢慢修炼成为一个全栈工程师，虽然不用样样精通，但必须至少在一个方面是专家，并且对其他方向有一定的了解。下面就记录一下在浏览器中嵌入视频流的解决方案。


<!-- {% note info %}  -->
**[维基百科](https://zh.wikipedia.org/wiki/Motion_JPEG)**对M-JPEG的介绍：
　　M-JPEG只使用帧内压缩（区别于算法更复杂的帧间压缩），只单独的对某一帧进行压缩，而不考虑视频画面中不同帧之间的变化。因此压缩效率比较低，一般低于1:20，而使用了帧间压缩的现代视频压缩格式（如MPEG1、MPEG2和H.264/MPEG-4 AVC）一般能超过1:50。由于各帧直接是相互独立的，M-JPEG的编解码在对运算能力和内存的要求较低。
　　由于M-JPEG是纯粹的帧内压缩，每帧画面的质量只与编码率和画面的空域复杂度有关。包含大面积平滑变化或者单色区域的帧压缩效果较好，而包含复杂纹理、细线条（如文字）的区域容易产生由于离散余弦变换产生的噪声。M-JPEG的压缩效果与视频的时域复杂度无关。
<!-- {% endnote %} -->


<iframe src="//www.slideshare.net/slideshow/embed_code/key/bAlwYpbWDpmNKM" width="720" height="480" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/seldon_io/tensorflow-london-14-ben-hall-machine-learning-workloads-with-kubernetes-and-kubeflow" title="TensorFlow London 14: Ben Hall &#x27;Machine Learning Workloads with Kubernetes and Kubeflow&#x27;" target="_blank">TensorFlow London 14: Ben Hall &#x27;Machine Learning Workloads with Kubernetes and Kubeflow&#x27;</a> </strong> from <strong><a href="https://www.slideshare.net/seldon_io" target="_blank">Seldon</a></strong> </div>

multipart视频流的content type必须是`multipart/x-mixed-replace`，如下所示，其中`--frame`作为标识符分隔每一帧图像。
```html
HTTP/1.1 200 OK
Content-Type: multipart/x-mixed-replace; boundary=frame

--frame
Content-Type: image/jpeg

<jpeg data here>
--frame
Content-Type: image/jpeg

<jpeg data here>
...
```


```python
class BaseCamera(object):
    thread = None  # background thread that reads frames from camera
    frame = None  # current frame is stored here by background thread
    last_access = 0  # time of last client access to the camera
    event = CameraEvent()

    def __init__(self):
        """Start the background camera thread if it isn't running yet."""
        if BaseCamera.thread is None:
            BaseCamera.last_access = time.time()

            # start background frame thread
            BaseCamera.thread = threading.Thread(target=self._thread)
            BaseCamera.thread.start()

            # wait until frames are available
            while self.get_frame() is None:
                time.sleep(0)

    def get_frame(self):
        """Return the current camera frame."""
        BaseCamera.last_access = time.time()

        # wait for a signal from the camera thread
        BaseCamera.event.wait()
        BaseCamera.event.clear()

        return BaseCamera.frame

    @staticmethod
    def frames():
        """Generator that returns frames from the camera."""
        raise RuntimeError('Must be implemented by subclasses.')

    @classmethod
    def _thread(cls):
        """Camera background thread."""
        print('Starting camera thread.')
        frames_iterator = cls.frames()
        for frame in frames_iterator:
            BaseCamera.frame = frame
            BaseCamera.event.set()  # send signal to clients
            time.sleep(0)

            # if there hasn't been any clients asking for frames in
            # the last 10 seconds then stop the thread
            if time.time() - BaseCamera.last_access > 10:
                frames_iterator.close()
                print('Stopping camera thread due to inactivity.')
                break
        BaseCamera.thread = None
```



```python
import cv2
from base_camera import BaseCamera


class Camera(BaseCamera):
    video_source = 0

    @staticmethod
    def set_video_source(source):
        Camera.video_source = source

    @staticmethod
    def frames():
        camera = cv2.VideoCapture(Camera.video_source)
        if not camera.isOpened():
            raise RuntimeError('Could not start camera.')

        while True:
            # read current frame
            _, img = camera.read()

            # encode as a jpeg image and return it
            yield cv2.imencode('.jpg', img)[1].tobytes()
```




<!-- ### 参考 -->
<!-- {% note primary %} 参考 {% endnote %} -->
[1] https://blog.miguelgrinberg.com/post/flask-video-streaming-revisited
[2] https://github.com/miguelgrinberg/flask-video-streaming
